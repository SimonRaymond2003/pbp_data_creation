---
title: "read_pffs"
output: html_document
date: "2024-12-18"
---

```{r}
library(dplyr)
library(stringr)
library(purrr)
library(digest)  # For creating file hashes

# Function to get file hash
get_file_hash <- function(file_path) {
  tryCatch({
    file_content <- readLines(file_path)
    return(digest::digest(file_content))
  }, error = function(e) {
    cat("Error reading file for hash:", file_path, "\nError message:", e$message, "\n")
    return(NULL)
  })
}

# Function to check for duplicate files
check_duplicate_files <- function(csv_files) {
  if (length(csv_files) <= 1) return(list())
  
  # Create a list to store file hashes
  file_hashes <- list()
  duplicate_groups <- list()
  
  # Calculate hash for each file
  for (file_path in csv_files) {
    hash <- get_file_hash(file_path)
    if (!is.null(hash)) {
      if (hash %in% names(file_hashes)) {
        file_hashes[[hash]] <- c(file_hashes[[hash]], file_path)
      } else {
        file_hashes[[hash]] <- file_path
      }
    }
  }
  
  # Find duplicates
  duplicate_groups <- file_hashes[sapply(file_hashes, length) > 1]
  
  return(duplicate_groups)
}

# Function to analyze CSV files in a folder
analyze_and_combine_csvs <- function(folder_path) {
  # Get all CSV files in the folder
  csv_files <- list.files(path = folder_path, pattern = "*.csv", full.names = TRUE)
  
  # Report how many CSV files are in the folder
  num_csv_files <- length(csv_files)
  cat("Number of CSV files in the folder:", num_csv_files, "\n")
  
  if (num_csv_files == 0) {
    cat("No CSV files found in the folder:", folder_path, "\n")
    return(NULL)
  }
  
  # Check for duplicate files
  duplicate_groups <- check_duplicate_files(csv_files)
  if (length(duplicate_groups) > 0) {
    cat("\nWARNING: Found duplicate files in folder:", folder_path, "\n")
    for (i in seq_along(duplicate_groups)) {
      cat("\nDuplicate group", i, ":\n")
      cat(basename(duplicate_groups[[i]]), sep = "\n")
    }
    cat("\n")
  }
  
  # Extract the year from the folder path
  year <- str_extract(folder_path, "(19|20)\\d{2}")
  
  if (is.na(year)) {
    cat("Warning: No valid year found in folder path:", folder_path, "\n")
    year <- NA
  }
  
  # Initialize a list to store the combined data
  combined_data_list <- list()
  
  # Iterate through all CSV files
  for (file_path in csv_files) {
    tryCatch({
      # Extract the file name (without the path)
      file_name <- basename(file_path)
      
      # Check if the file name contains a week number (e.g., "(12)")
      week_match <- str_extract(file_name, "\\(\\d{1,2}\\)")
      
      # If a week number is found, add 1 to it (since (12) means week 13)
      if (!is.na(week_match)) {
        week <- as.numeric(str_extract(week_match, "\\d+")) + 1
      } else {
        # If no week number is found, it's week 1
        week <- 1
      }
      
      # Read the CSV file
      file_data <- read.csv(file_path)
      
      # Add columns for week and year
      file_data <- file_data %>%
        mutate(week = week, year = year)
      
      # Append the data to the list
      combined_data_list[[file_name]] <- file_data
      
    }, error = function(e) {
      cat("Error processing file:", file_path, "\nError message:", e$message, "\n")
    })
  }
  
  if (length(combined_data_list) == 0) {
    cat("No data was successfully loaded from:", folder_path, "\n")
    return(NULL)
  }
  
  # Combine all CSV files into one data frame
  combined_data <- bind_rows(combined_data_list)
  
  cat("Successfully combined", length(combined_data_list), "CSV files into one data frame.\n")
  
  return(combined_data)
}

# Function to load data for all years
load_pff_data <- function(base_path, years = 2016:2023) {
  # Define all report categories and their subdirectories
  report_categories <- list(
    blocking = list(
      path = "Blocking_Reports",
      reports = c("Blocking_Grades", "Run_Blocking", "Pass_Blocking")
    ),
    defense = list(
      path = "Defensive_Reports",
      reports = c("Coverage_Grades", "Coverage_Schemes", "Defensive_Grades",
                 "Pass_Rush_Grades", "Pass_Rushing_Productivity", "Run_Defense_Grades",
                 "Slot_Coverage")
    ),
    passing = list(
      path = "Passing_Reports",
      reports = c("Allowed_Pressure", "Passing_Concept", "Passing_Depth",
                 "Passing_Grades", "Passing_Pressure", "Time_In_Pocket")
    ),
    receiving = list(
      path = "Receiving_Reports",
      reports = c("Receiving_Concept", "Receiving_Depth", "Receiving_Grades",
                 "Receiving_Vs_Scheme")
    ),
    rushing = list(
      path = "Rushing_Reports",
      reports = c("Rushing_Grades")
    ),
    special_teams = list(
      path = "Special_Teams_Reports",
      reports = c("Field_Goals_Grades", "Kickoff_and_Punt_Return_Grades",
                 "Kickoff_Grades", "Punting_Grades", "Special_Teams_Grades")
    )
  )
  
  # Initialize a list to store all data and count successful loads
  all_data <- list()
  report_counts <- list()
  
  # Loop through each year
  for (year in years) {
    cat("\nProcessing year:", year, "\n")
    report_counts[[as.character(year)]] <- 0
    
    # Loop through each category
    for (category_name in names(report_categories)) {
      category <- report_categories[[category_name]]
      
      # Loop through each report type
      for (report in category$reports) {
        # Construct the full path
        folder_path <- file.path(base_path, 
                               category$path, 
                               paste0(gsub("Receiving", "Receiving", category$path), "_", year),
                               paste0(report, "_", year))
        
        # Check if directory exists
        if (!dir.exists(folder_path)) {
          cat("Directory does not exist:", folder_path, "\n")
          next
        }
        
        # Create a variable name for the data
        var_name <- tolower(paste0(report, "_data_", year))
        var_name <- gsub("-", "_", var_name)
        
        cat("\nLoading:", var_name, "\n")
        
        # Load the data
        data <- analyze_and_combine_csvs(folder_path)
        
        # Store the data in the list if it's not NULL
        if (!is.null(data)) {
          all_data[[var_name]] <- data
          report_counts[[as.character(year)]] <- report_counts[[as.character(year)]] + 1
        }
      }
    }
  }
  
  # Print summary of loaded data and report counts
  cat("\nSummary of loaded datasets:\n")
  for (name in names(all_data)) {
    cat(sprintf("%s: %d rows\n", name, nrow(all_data[[name]])))
  }
  
  cat("\nNumber of reports loaded per year:\n")
  for (year in names(report_counts)) {
    cat(sprintf("Year %s: %d reports\n", year, report_counts[[year]]))
  }
  
  return(all_data)
}
```


```{r}
# Example usage:
 base_path <- "C:/Users/simon/Dropbox/Uni_24_25/Honours_Research/PFF_Data"
 all_pff_data <- load_pff_data(base_path)
```

```{r}
# Function to create expanded PFF stats with correct week ranges
create_pff_stats <- function(players_df, unique_columns) {
  cat("Creating expanded PFF stats...\n")
  
  # Create all possible year/week combinations
  years <- 2016:2023
  weeks <- list()
  for(year in years) {
    weeks[[as.character(year)]] <- 1:if(year >= 2021) 18 else 17
  }
  
  cat("Creating base structure...\n")
  # Create base dataframe with player-year-week combinations
  pff_stats <- players_df %>%
    # Create a row for each year
    tidyr::crossing(year = years) %>%
    # Create a row for each week
    group_by(player_id, player, year) %>%
    tidyr::expand(week = 1:18) %>%
    ungroup() %>%
    # Remove week 18 for years 2020 and earlier
    filter(!(year <= 2020 & week == 18)) %>%
    # Sort the data
    arrange(player_id, year, week)
  
  # Add all unique columns with NA values
  cat("Adding", length(unique_columns), "columns with NA values...\n")
  for(col in unique_columns) {
    pff_stats[[col]] <- NA
  }
  
  # Print summary statistics
  cat("\nSummary Statistics:\n")
  cat("Total unique players:", length(unique(pff_stats$player_id)), "\n")
  cat("Total rows:", nrow(pff_stats), "\n")
  cat("Total columns:", ncol(pff_stats), "\n")
  
  # Show column types
  cat("\nColumn type summary:\n")
  col_types <- sapply(pff_stats, class)
  print(table(col_types))
  
  return(pff_stats)
}
```



```{r}
# First get all unique columns from all dataframes
get_unique_columns <- function() {
  cat("Getting unique columns from all dataframes...\n")
  all_dfs <- list(
    # Existing reports
    blocking_grades = blocking_grades,
    run_blocking = run_blocking,
    pass_blocking = pass_blocking,
    coverage_grades = coverage_grades,
    coverage_schemes = coverage_schemes,
    defensive_grades = defensive_grades,
    pass_rush_grades = pass_rush_grades,
    pass_rushing_productivity = pass_rushing_productivity,
    run_defense_grades = run_defense_grades,
    slot_coverage = slot_coverage,
    allowed_pressure = allowed_pressure,
    passing_concept = passing_concept,
    passing_depth = passing_depth,
    passing_grades = passing_grades,
    passing_pressure = passing_pressure,
    time_in_pocket = time_in_pocket,
    receiving_concept = receiving_concept,
    receiving_depth = receiving_depth,
    receiving_grades = receiving_grades,
    receiving_vs_scheme = receiving_vs_scheme,
    rushing_grades = rushing_grades,
    # Special Teams reports
    field_goals_grades = field_goals_grades,
    kickoff_and_punt_return_grades = kickoff_and_punt_return_grades,
    kickoff_grades = kickoff_grades,
    punting_grades = punting_grades,
    special_teams_grades = special_teams_grades
  )
  
  # Get all unique column names, excluding player_id, player, year, and week
  cat("Processing dataframes to get unique columns...\n")
  all_columns <- unique(unlist(lapply(all_dfs, colnames)))
  all_columns <- setdiff(all_columns, c("player_id", "player", "year", "week"))
  
  cat("Found", length(all_columns), "unique columns\n")
  return(all_columns)
}

fill_pff_stats_fast_dplyr <- function(pff_stats) {
  # Create list of all report dataframes
  reports <- list(
    # Existing reports
    blocking_grades = blocking_grades,
    run_blocking = run_blocking,
    pass_blocking = pass_blocking,
    coverage_grades = coverage_grades,
    coverage_schemes = coverage_schemes,
    defensive_grades = defensive_grades,
    pass_rush_grades = pass_rush_grades,
    pass_rushing_productivity = pass_rushing_productivity,
    run_defense_grades = run_defense_grades,
    slot_coverage = slot_coverage,
    allowed_pressure = allowed_pressure,
    passing_concept = passing_concept,
    passing_depth = passing_depth,
    passing_grades = passing_grades,
    passing_pressure = passing_pressure,
    time_in_pocket = time_in_pocket,
    receiving_concept = receiving_concept,
    receiving_depth = receiving_depth,
    receiving_grades = receiving_grades,
    receiving_vs_scheme = receiving_vs_scheme,
    rushing_grades = rushing_grades,
    # Special Teams reports
    field_goals_grades = field_goals_grades,
    kickoff_and_punt_return_grades = kickoff_and_punt_return_grades,
    kickoff_grades = kickoff_grades,
    punting_grades = punting_grades,
    special_teams_grades = special_teams_grades
  )
  
  total_reports <- length(reports)
  cat("\nTotal reports to process:", total_reports, "\n")
  
  # Process each report
  for(report_name in names(reports)) {
    cat(sprintf("\nProcessing %s...", report_name))
    report_df <- reports[[report_name]]
    
    # Convert year and week to integer in report_df if they exist
    if("year" %in% names(report_df)) report_df$year <- as.integer(report_df$year)
    if("week" %in% names(report_df)) report_df$week <- as.integer(report_df$week)
    
    # Get columns that exist in both dataframes, excluding key columns
    key_cols <- c("player_id", "player", "year", "week")
    cols_to_rename <- setdiff(names(report_df), key_cols)
    
    # Create a new dataframe with renamed columns
    renamed_df <- report_df
    
    # Rename columns by adding report prefix
    for(col in cols_to_rename) {
      new_name <- paste0(report_name, "_", col)
      names(renamed_df)[names(renamed_df) == col] <- new_name
    }
    
    # Join with existing data
    pff_stats <- pff_stats %>%
      left_join(
        renamed_df %>% select(-player),  # Exclude player name to avoid duplicates
        by = c("player_id", "year", "week")
      )
    
    cat(" done\n")
  }
  
  cat("Processing complete!\n")
  return(pff_stats)
}

# Function to get unique players - updated to include special teams
get_unique_players <- function() {
  # Create a list of all dataframes
  all_dfs <- list(
    # Existing reports
    blocking_grades = blocking_grades,
    run_blocking = run_blocking,
    pass_blocking = pass_blocking,
    coverage_grades = coverage_grades,
    coverage_schemes = coverage_schemes,
    defensive_grades = defensive_grades,
    pass_rush_grades = pass_rush_grades,
    pass_rushing_productivity = pass_rushing_productivity,
    run_defense_grades = run_defense_grades,
    slot_coverage = slot_coverage,
    allowed_pressure = allowed_pressure,
    passing_concept = passing_concept,
    passing_depth = passing_depth,
    passing_grades = passing_grades,
    passing_pressure = passing_pressure,
    time_in_pocket = time_in_pocket,
    receiving_concept = receiving_concept,
    receiving_depth = receiving_depth,
    receiving_grades = receiving_grades,
    receiving_vs_scheme = receiving_vs_scheme,
    rushing_grades = rushing_grades,
    # Special Teams reports
    field_goals_grades = field_goals_grades,
    kickoff_and_punt_return_grades = kickoff_and_punt_return_grades,
    kickoff_grades = kickoff_grades,
    punting_grades = punting_grades,
    special_teams_grades = special_teams_grades
  )
  
  # Initialize empty list to store player info from each dataframe
  player_info_list <- list()
  
  # Process each dataframe
  for(df_name in names(all_dfs)) {
    df <- all_dfs[[df_name]]
    
    # Check if dataframe has both player ID and name columns
    if("player_id" %in% colnames(df) && "player" %in% colnames(df)) {
      player_info <- df %>%
        select(player_id, player) %>%
        distinct()
      
      player_info_list[[df_name]] <- player_info
    }
  }
  
  # Combine all player info and remove duplicates
  all_players <- bind_rows(player_info_list) %>%
    distinct() %>%
    arrange(player_id)
  
  # Print summary
  cat("Total unique players:", nrow(all_players), "\n")
  
  return(all_players)
}
```

```{r}
# Blocking reports
blocking_grades <- bind_rows(Filter(function(x) grepl("blocking_grades_", names(all_pff_data)), all_pff_data))
run_blocking <- bind_rows(Filter(function(x) grepl("run_blocking_", names(all_pff_data)), all_pff_data))
pass_blocking <- bind_rows(Filter(function(x) grepl("pass_blocking_", names(all_pff_data)), all_pff_data))

# Defense reports 
coverage_grades <- bind_rows(Filter(function(x) grepl("coverage_grades_", names(all_pff_data)), all_pff_data))
coverage_schemes <- bind_rows(Filter(function(x) grepl("coverage_schemes_", names(all_pff_data)), all_pff_data))
defensive_grades <- bind_rows(Filter(function(x) grepl("defensive_grades_", names(all_pff_data)), all_pff_data))
pass_rush_grades <- bind_rows(Filter(function(x) grepl("pass_rush_grades_", names(all_pff_data)), all_pff_data))
pass_rushing_productivity <- bind_rows(Filter(function(x) grepl("pass_rushing_productivity_", names(all_pff_data)), all_pff_data))
run_defense_grades <- bind_rows(Filter(function(x) grepl("run_defense_grades_", names(all_pff_data)), all_pff_data))
slot_coverage <- bind_rows(Filter(function(x) grepl("slot_coverage_", names(all_pff_data)), all_pff_data))

# Passing reports
allowed_pressure <- bind_rows(Filter(function(x) grepl("allowed_pressure_", names(all_pff_data)), all_pff_data))
passing_concept <- bind_rows(Filter(function(x) grepl("passing_concept_", names(all_pff_data)), all_pff_data))
passing_depth <- bind_rows(Filter(function(x) grepl("passing_depth_", names(all_pff_data)), all_pff_data))
passing_grades <- bind_rows(Filter(function(x) grepl("passing_grades_", names(all_pff_data)), all_pff_data))
passing_pressure <- bind_rows(Filter(function(x) grepl("passing_pressure_", names(all_pff_data)), all_pff_data))
time_in_pocket <- bind_rows(Filter(function(x) grepl("time_in_pocket_", names(all_pff_data)), all_pff_data))

# Receiving reports
receiving_concept <- bind_rows(Filter(function(x) grepl("receiving_concept_", names(all_pff_data)), all_pff_data))
receiving_depth <- bind_rows(Filter(function(x) grepl("receiving_depth_", names(all_pff_data)), all_pff_data))
receiving_grades <- bind_rows(Filter(function(x) grepl("receiving_grades_", names(all_pff_data)), all_pff_data))
receiving_vs_scheme <- bind_rows(Filter(function(x) grepl("receiving_vs_scheme_", names(all_pff_data)), all_pff_data))

# Rushing reports
rushing_grades <- bind_rows(Filter(function(x) grepl("rushing_grades_", names(all_pff_data)), all_pff_data))

# Special Teams reports
field_goals_grades <- bind_rows(Filter(function(x) grepl("field_goals_grades_", names(all_pff_data)), all_pff_data))
kickoff_and_punt_return_grades <- bind_rows(Filter(function(x) grepl("kickoff_and_punt_return_grades_", names(all_pff_data)), all_pff_data))
kickoff_grades <- bind_rows(Filter(function(x) grepl("kickoff_grades_", names(all_pff_data)), all_pff_data))
punting_grades <- bind_rows(Filter(function(x) grepl("punting_grades_", names(all_pff_data)), all_pff_data))
special_teams_grades <- bind_rows(Filter(function(x) grepl("special_teams_grades_", names(all_pff_data)), all_pff_data))
```


```{r}
# Get unique players
players_df <- get_unique_players()

# Get unique columns
unique_columns <- get_unique_columns()

# Create the base PFF stats dataframe
pff_stats <- create_pff_stats(players_df, unique_columns)
```


```{r}
# Fill the stats with all data
pff_stats <- fill_pff_stats_fast_dplyr(pff_stats)
```



# write to a csv 

```{r}
library(data.table)
fwrite(pff_stats, "pff_stats.csv.gz", compress="gzip")
```

# viewing pff stats

first row to 100th row
```{r}
r1 <- pff_stats[1:10000, ]
```

# cleaning 

```{r}
# Function to clean PFF stats by removing empty rows with progress tracking
clean_pff_stats <- function(pff_stats) {

    library(progress)

  
  cat("Starting PFF stats cleaning process...\n")
  
  # Get initial dimensions
  initial_rows <- nrow(pff_stats)
  initial_cols <- ncol(pff_stats)
  
  # Create progress bar
  pb <- progress_bar$new(
    format = "Processing [:bar] :percent eta: :eta",
    total = initial_rows,
    clear = FALSE,
    width = 60
  )
  
  # Identify columns to exclude from NA check
  exclude_cols <- c("player_id", "player", "year", "week")
  
  # Calculate the number of non-NA values for each row with progress tracking
  cat("\nChecking rows for non-NA values...\n")
  rows_with_data <- logical(initial_rows)
  
  # Process in chunks for better progress tracking
  chunk_size <- 10000
  chunks <- split(1:initial_rows, ceiling(seq_along(1:initial_rows)/chunk_size))
  
  for(chunk in chunks) {
    # Process current chunk
    chunk_data <- pff_stats[chunk, !(names(pff_stats) %in% exclude_cols)]
    rows_with_data[chunk] <- apply(chunk_data, 1, function(row) sum(!is.na(row))) > 0
    
    # Update progress bar
    pb$tick(length(chunk))
  }
  
  cat("\nFiltering rows...\n")
  # Filter the dataframe to keep only rows with at least one non-NA value
  cleaned_stats <- pff_stats[rows_with_data, ]
  
  # Calculate statistics
  final_rows <- nrow(cleaned_stats)
  rows_removed <- initial_rows - final_rows
  removal_percentage <- (rows_removed / initial_rows) * 100
  
  # Print summary statistics
  cat("\nCleaning Summary:\n")
  cat("Initial rows:", initial_rows, "\n")
  cat("Final rows:", final_rows, "\n")
  cat("Rows removed:", rows_removed, "\n")
  cat("Percentage removed:", sprintf("%.2f%%", removal_percentage), "\n")
  
  # Calculate and print player statistics
  initial_players <- length(unique(pff_stats$player_id))
  final_players <- length(unique(cleaned_stats$player_id))
  players_removed <- initial_players - final_players
  
  cat("\nPlayer Statistics:\n")
  cat("Initial unique players:", initial_players, "\n")
  cat("Final unique players:", final_players, "\n")
  cat("Players completely removed:", players_removed, "\n")
  
  # Return the cleaned dataframe
  return(cleaned_stats)
}
```

```{r}
# Clean the PFF stats with progress tracking
cpff_stats <- clean_pff_stats(pff_stats)
```

```{r}
# Write the cleaned PFF stats to a CSV file
fwrite(cpff_stats, "cpff_stats.csv.gz", compress = "gzip")
```
